# SPECIFICA COMPLETA SUITE DI ANALISI - BoloGAN Energy & Performance

**Data:** 2025-11-18
**Versione:** 1.0 - Specifica Finale
**Status:** Definitiva per implementazione

---

## üìã INDICE

1. [Obiettivi e Contesto](#1-obiettivi-e-contesto)
2. [Metriche da Calcolare](#2-metriche-da-calcolare)
3. [Grafici da Generare](#3-grafici-da-generare)
4. [Correlazioni da Analizzare](#4-correlazioni-da-analizzare)
5. [Scelte Tecniche](#5-scelte-tecniche)
6. [Struttura Output](#6-struttura-output)
7. [Architettura Software](#7-architettura-software)
8. [Piano di Implementazione](#8-piano-di-implementazione)

---

## 1. OBIETTIVI E CONTESTO

### 1.1 Scopo della Suite

Sviluppare una suite Python completa per l'analisi dei dati di monitoring raccolti durante training/evaluation di BoloGAN, con focus su:

1. **Caratterizzazione energetica**: Consumo, potenza, efficienza
2. **Analisi performance**: Throughput, utilizzo risorse, bottleneck
3. **Correlazioni monitoring ‚Üî training**: Dinamiche energetiche durante training
4. **Overhead monitoring**: Quantificare il costo dell'osservabilit√† (feature unica)
5. **Identificazione ottimizzazioni**: Pareto frontiers, sweet spots, scalability

### 1.2 Riferimenti

- **Struttura tesi**: Capitolo 3 "Analisi computazionale ed energetica"
- **Dati monitorati**: Vedi `results/oph/monitoring/MONITORING_DATA_ANALYSIS.md`
- **Metriche standard**: Energy-per-1000-events, Performance-per-Watt (Green AI literature)

### 1.3 Contributi Originali

1. **Auto-monitoring**: Misurazione overhead del monitoring stesso
2. **Power vs Loss correlation**: Dinamiche energetiche correlate a training phases
3. **Workload characterization**: IPC vs I/O wait per identificare bottleneck type
4. **Pareto analysis**: Trade-off energia/performance/qualit√†

---

## 2. METRICHE DA CALCOLARE

### 2.1 Metriche Computazionali (Performance)

| Metrica | Formula | File Sorgente | Priorit√† | Note |
|---------|---------|---------------|----------|------|
| **Training Time** | `end_time - start_time` | `execution_summary.json` | ‚≠ê‚≠ê‚≠ê | Durata totale esperimento |
| **Throughput** | `total_samples / duration_s` | `stdout.log` + `summary.json` | ‚≠ê‚≠ê‚≠ê | samples/second |
| **Iteration Throughput** | Parse `Iter: X; TotalTime: Y` | `stdout.log` | ‚≠ê‚≠ê | iterations/second |
| **CPU Utilization** | `us + sy` (%) | `vmstat.csv` | ‚≠ê‚≠ê‚≠ê | Media e picco |
| **Memory Footprint** | `rss` (MB) | `process_pidstat.csv` | ‚≠ê‚≠ê | Peak memory |
| **I/O Throughput** | `rkB/s + wkB/s` | `iostat_dev.csv` | ‚≠ê‚≠ê | Bottleneck I/O detection |
| **IPC** | `instructions / cycles` | `perf.csv` | ‚≠ê‚≠ê‚≠ê | Efficienza microarchitetturale |
| **Cache Hit Rate** | `(refs - miss) / refs √ó 100` | `perf.csv` | ‚≠ê‚≠ê | % cache efficiency |

**Formule parsing stdout.log:**
```python
# Throughput per iteration
pattern = r'Iter: (\d+); .*TotalTime: ([\d.]+)'
iter_per_s = iteration / total_time

# Training samples
pattern = r'Training size X: \((\d+), \d+\)'
total_samples = int(match.group(1))
```

### 2.2 Metriche Energetiche (Energy)

| Metrica | Formula | File Sorgente | Priorit√† | Standard |
|---------|---------|---------------|----------|----------|
| **Potenza Istantanea** | `ŒîE / Œît` (Watt) | `energy_rapl.csv` | ‚≠ê‚≠ê‚≠ê | Power profile |
| **Potenza Media** | `mean(P(t))` | Derivata da RAPL | ‚≠ê‚≠ê‚≠ê | Baseline metrica |
| **Energia Totale** | `sum(ŒîE)` con overflow handling | `energy_rapl.csv` | ‚≠ê‚≠ê‚≠ê | Joule totali |
| **Energia per Epoca** | `E_total / num_epochs` | RAPL + stdout parsing | ‚≠ê‚≠ê | Normalizzazione |
| **Energy-per-1000-events** | `E_total / (samples/1000)` | RAPL + stdout | ‚≠ê‚≠ê‚≠ê | **Confronto GEANT4** |
| **Energy Breakdown** | `E_CPU / (E_CPU+E_DRAM) √ó 100` | RAPL (package vs dram) | ‚≠ê‚≠ê‚≠ê | Workload type |

**Gestione Overflow RAPL:**
```python
def handle_rapl_overflow(energy_series):
    """
    RAPL counters: 32-bit, overflow ~262s @ 100W
    Detection: E[i+1] < E[i]
    Correction: E_real = (2^32 - E[i]) + E[i+1]
    """
    MAX_RAPL = 2**32  # microJoules
    corrected = []
    cumulative = 0
    for i in range(len(energy_series)):
        if i > 0 and energy_series[i] < energy_series[i-1]:
            # Overflow detected
            delta = (MAX_RAPL - energy_series[i-1]) + energy_series[i]
        else:
            delta = energy_series[i] - (energy_series[i-1] if i > 0 else 0)
        cumulative += delta
        corrected.append(cumulative)
    return corrected
```

### 2.3 Metriche di Efficienza (Efficiency)

| Metrica | Formula | Priorit√† | Uso Tesi |
|---------|---------|----------|----------|
| **Performance-per-Watt** | `throughput / P_avg` (samples/s/W) | ‚≠ê‚≠ê‚≠ê | **Standard Green AI** |
| **samples/Joule** | `total_samples / E_total` | ‚≠ê‚≠ê‚≠ê | Efficienza energetica |
| **Energy-Delay Product** | `E_total √ó T¬≤` | ‚≠ê‚≠ê | Trade-off energia/tempo |

**Note:** ~~Thermal Efficiency~~ esclusa (richiede T_ambient preciso non disponibile)

### 2.4 Metriche Overhead Monitoring üÜï

| Metrica | Formula | File Sorgente | Feature Unica |
|---------|---------|---------------|---------------|
| **Monitoring CPU Overhead** | `sum(mon_cpu%) / total_cpu% √ó 100` | `monitoring_overhead.csv` + `vmstat` | ‚úÖ Tesi |
| **Monitoring Memory** | `sum(mon_rss)` MB | `monitoring_overhead.csv` | ‚úÖ |
| **Per-Monitor Cost** | CPU% per tool | Group by command | ‚úÖ |

**Breakdown per tool:**
- vmstat, iostat, free (system monitoring)
- pidstat (process monitoring)
- perf (performance counters)
- RAPL monitoring (AWK pipelines)

### 2.5 Metriche ML Training (per correlazioni)

| Metrica | Fonte | Parsing | Uso |
|---------|-------|---------|-----|
| **Generator Loss** | `stdout.log` | `Gloss: ([\d.-]+)` | Correlazioni energia |
| **Discriminator Loss** | `stdout.log` | `Dloss: ([\d.-]+)` | Correlazioni energia |
| **Training Stability** | Loss variance | `std(Gloss)` | Convergence analysis |

### 2.6 Metriche Derivate (Correlazioni)

| Metrica | Formula | Uso |
|---------|---------|-----|
| **Workload Type** | `if IPC > 1.0 and iowait < 5%: "compute-bound"` | Characterization |
| **Thermal Throttling Events** | `count(freq < base_freq)` | Performance degradation |
| **I/O Bottleneck Score** | `iowait √ó (1/IPC)` | Bottleneck severity |

---

## 3. GRAFICI DA GENERARE

### 3.1 TOP 11 Grafici Must-Have

#### **Grafico 1: Power Profile** ‚≠ê‚≠ê‚≠ê
**Tipo:** Time-Series
**Descrizione:** Andamento potenza istantanea nel tempo

- **X-axis:** Time (seconds)
- **Y-axis:** Power (Watt)
- **Series:**
  - Total Power (package_0 + package_1 + dram_0 + dram_1)
  - CPU Power (package_0 + package_1)
  - DRAM Power (dram_0 + dram_1)
- **Varianti:**
  - `power_profile.png`: Total only
  - `power_profile_detailed.png`: Breakdown CPU/DRAM
- **Output:** `analysis/plots/power_profile.png`
- **Uso tesi:** Sezione 3.5.2 "Power profiles"

---

#### **Grafico 2: Energy Breakdown** ‚≠ê‚≠ê‚≠ê
**Tipo:** Pie Chart
**Descrizione:** Composizione energia totale per componente

- **Slices:**
  - CPU Package 0 (Joule, %)
  - CPU Package 1 (Joule, %)
  - DRAM 0 (Joule, %)
  - DRAM 1 (Joule, %)
- **Annotations:** Valore assoluto + percentuale
- **Output:** `analysis/plots/energy_breakdown.png`
- **Uso tesi:** Sezione 3.5.2 "Energy breakdown: CPU vs memory"
- **Interpretazione:**
  - CPU > 70% ‚Üí Compute-intensive workload
  - DRAM > 40% ‚Üí Memory-intensive workload

---

#### **Grafico 3: Frequency vs Power** ‚≠ê‚≠ê‚≠ê
**Tipo:** Scatter Plot + Linear Regression
**Descrizione:** Correlazione frequenza CPU e potenza (DVFS analysis)

- **X-axis:** Average CPU Frequency (MHz)
- **Y-axis:** Total Power (Watt)
- **Points:** Temporal samples (1s resolution)
- **Regression:** Linear fit: `P = a√óf + b`
- **Annotations:**
  - R¬≤ (coefficient of determination)
  - Equation: `P = 0.15√óf + 20W`
- **Output:** `analysis/plots/frequency_vs_power.png`
- **Uso tesi:** Sezione 3.4.3 "CPU frequency scaling: analisi DVFS"
- **Teorico:** P ‚àù f¬≥ (dinamica), P ‚àù f (statica+dinamica)

---

#### **Grafico 4: Memory Usage** ‚≠ê‚≠ê
**Tipo:** Stacked Area Time-Series
**Descrizione:** Evoluzione utilizzo memoria nel tempo

- **X-axis:** Time (seconds)
- **Y-axis:** Memory (GB)
- **Stacked areas:**
  - Used (bottom)
  - Buff/Cache (middle)
  - Free (top)
- **Total line:** Total RAM (horizontal reference)
- **Output:** `analysis/plots/memory_usage.png`
- **Uso tesi:** Sezione 3.5 "Memory Usage Evolution"
- **Alerts:** Memory leak if linear growth in "Used"

---

#### **Grafico 5: Thermal Analysis** ‚≠ê‚≠ê
**Tipo:** Multi-Axis Time-Series (Triple)
**Descrizione:** Correlazione temperatura, potenza, frequenza

- **X-axis:** Time (seconds)
- **Y-axis Left (primary):** Temperature (¬∞C) - thermal_zone0, thermal_zone1
- **Y-axis Right 1:** Power (Watt) - Total power
- **Y-axis Right 2:** Frequency (MHz) - Average CPU frequency
- **Output:** `analysis/plots/thermal_analysis.png`
- **Uso tesi:** Sezione 3.4.3 "Thermal throttling"
- **Detection:** Temp spike ‚Üí Freq drop (throttling event)

---

#### **Grafico 6: Monitoring Overhead** ‚≠ê‚≠ê‚≠ê
**Tipo:** Horizontal Bar Chart
**Descrizione:** CPU overhead per tool di monitoring

- **Y-axis:** Tool name (vmstat, iostat, pidstat, perf, rapl, free, ...)
- **X-axis:** Average CPU% usage
- **Bars:** Sorted by CPU% (descending)
- **Annotation:** Total overhead % in title
- **Output:** `analysis/plots/monitoring_overhead.png`
- **Uso tesi:** Sezione 3.8 "Cost of Observability" (feature unica!)

---

#### **Grafico 7: Loss Evolution** ‚≠ê
**Tipo:** Time-Series
**Descrizione:** Evoluzione loss durante training

- **X-axis:** Iteration number
- **Y-axis:** Loss value
- **Series:**
  - Generator Loss (Gloss) - solid line
  - Discriminator Loss (Dloss) - dashed line
- **Output:** `analysis/plots/loss_evolution.png`
- **Uso tesi:** Validazione convergenza training

---

#### **Grafico 8: Power vs Loss Evolution** ‚≠ê‚≠ê‚≠ê üÜï
**Tipo:** Dual-Axis Time-Series
**Descrizione:** Correlazione power e training dynamics

- **X-axis:** Time (seconds) o Iteration
- **Y-axis Left:** Power (Watt)
- **Y-axis Right:** Loss value
- **Series:**
  - Total Power (thick red line)
  - Gloss (blue line)
  - Dloss (green dashed line)
- **Output:** `analysis/plots/power_vs_loss_evolution.png`
- **Uso tesi:** Sezione 3.5.4 "Energy Dynamics During Training" (contributo originale!)
- **Analisi aggiuntiva:** Pearson correlation coefficient + p-value

---

#### **Grafico 9: Workload Characterization** ‚≠ê‚≠ê‚≠ê üÜï
**Tipo:** 2D Scatter Plot (Color-coded)
**Descrizione:** Identificazione bottleneck type (Compute vs I/O vs Memory)

- **X-axis:** IPC (Instructions Per Cycle)
- **Y-axis:** %iowait (I/O wait percentage)
- **Color:** Throughput (samples/s) - gradient colormap
- **Size:** Power (W) - bubble size
- **Regions annotated:**
  - Top-left: "I/O BOUND" (high iowait, low IPC)
  - Bottom-right: "COMPUTE BOUND" (low iowait, high IPC)
  - Center: "BALANCED"
- **Output:** `analysis/plots/workload_characterization.png`
- **Uso tesi:** Sezione 3.5.1 "Workload characteristics: compute-intensive vs memory-bound"

**Interpretazione:**
```
     %iowait
        ‚Üë
     10 |  ‚óè‚óè‚óè I/O BOTTLENECK
        |    ‚Üí Optimize data pipeline
      5 |         ‚óã BALANCED
        |
      0 |___________________‚óè‚óè‚óè COMPUTE BOUND
        0.0    0.5    1.0    1.5    2.0
                    IPC
```

---

#### **Grafico 10: Energy-Performance Trade-off** ‚≠ê‚≠ê‚≠ê üÜï
**Tipo:** Scatter Plot + Pareto Frontier
**Descrizione:** Trade-off velocit√† vs efficienza energetica

- **X-axis:** Throughput (samples/s)
- **Y-axis:** Energy Efficiency (samples/Joule)
- **Points:** Temporal snapshots (ogni 10s o per epoca)
- **Pareto Frontier:** Line connecting non-dominated points
- **Highlight:** Sweet spot (best trade-off)
- **Output:** `analysis/plots/energy_performance_tradeoff.png`
- **Uso tesi:** Sezione 3.7.2 "Pareto frontiers: performance vs energy"

**Interpretazione:**
- Top-right: IDEAL (fast AND efficient) - rare
- Top-left: Efficient but slow (low power)
- Bottom-right: Fast but inefficient (high power)

---

#### **Grafico 11: Performance Scalability** ‚≠ê‚≠ê üÜï
**Tipo:** Scatter Plot + Regression
**Descrizione:** CPU utilization vs throughput (scalability analysis)

- **X-axis:** CPU Utilization (%)
- **Y-axis:** Throughput (iterations/s)
- **Regression:** Piecewise linear fit
- **Annotations:**
  - Linear region slope
  - Saturation point (if detected)
- **Output:** `analysis/plots/performance_scalability.png`
- **Uso tesi:** Sezione 3.5.1 "Scalabilit√†: comportamento al variare delle risorse"

**Interpretazione:**
```
   Throughput
        ‚Üë
    0.5 |                ‚óè‚óè‚óè‚óè SATURATION
        |            ‚óè‚óè‚óè‚óè      (diminishing returns)
    0.3 |      ‚óè‚óè‚óè‚óè  LINEAR SCALING
        |  ‚óè‚óè‚óè‚óè       (efficient)
    0.1 |‚óè‚óè
        |________________________________‚Üí
         0%     25%     50%     75%    100%
                  CPU Utilization
```

---

### 3.2 Nice-to-Have Grafici (Priority 2)

#### **Grafico 12: Memory Pressure Impact**
- Dual-axis: Memory RSS + Throughput time-series
- Leak detection

#### **Grafico 13: Cache Impact on Performance**
- Scatter: Cache Hit Rate vs Throughput
- Quantifica cache miss impact

#### **Grafico 14: CPU Frequency Heatmap**
- X: Time, Y: Core ID, Color: Frequency
- Visualizza boost/throttling per core

---

## 4. CORRELAZIONI DA ANALIZZARE

### 4.1 Correlazioni Monitoring Interno

| ID | Correlazione | Variabili | Metodo | Output | Interpretazione |
|----|--------------|-----------|--------|--------|-----------------|
| C1 | **DVFS Impact** | Freq ‚Üî Power | Linear regression | Grafico 3 | Quantifica P ‚àù f, identifica DVFS efficiency |
| C2 | **Thermal Throttling** | Temp ‚Üî Freq | Time-series overlay | Grafico 5 | Detect throttling events (Temp>80¬∞C ‚Üí Freq drop) |
| C3 | **Workload Type** | IPC ‚Üî iowait | 2D scatter | Grafico 9 | Classify: Compute-bound vs I/O-bound vs Balanced |
| C4 | **Cache Efficiency** | Cache% ‚Üî IPC | Correlation | Report | High cache miss ‚Üí Low IPC (memory bottleneck) |

### 4.2 Correlazioni Monitoring ‚Üî Training

| ID | Correlazione | X | Y | Output | Insight |
|----|--------------|---|---|--------|---------|
| C5 | **Energy Dynamics** | Power | Gloss/Dloss | Grafico 8 | Training phase ‚Üí Power pattern? |
| C6 | **Performance Scalability** | CPU% | Throughput | Grafico 11 | Linear scaling or saturation? |
| C7 | **Memory Impact** | Memory RSS | Throughput | Grafico 12 | Memory pressure ‚Üí Performance drop? |
| C8 | **I/O Bottleneck** | %iowait | Throughput | Correlation | High iowait ‚Üí Slow training? |

### 4.3 Correlazioni Efficiency

| ID | Correlazione | X | Y | Output | Trade-off |
|----|--------------|---|---|--------|-----------|
| C9 | **Energy-Performance** | Throughput | samples/Joule | Grafico 10 | Pareto frontier: Optimal configurations |
| C10 | **Speed vs Efficiency** | samples/s | Performance-per-Watt | Scatter | Fast ‚â† Efficient (identify sweet spot) |

### 4.4 Metodi Statistici

**Pearson Correlation Coefficient:**
```python
from scipy.stats import pearsonr

r, p_value = pearsonr(power_series, gloss_series)
# r > 0.7: strong correlation
# p < 0.05: statistically significant
```

**Pareto Frontier Calculation:**
```python
def compute_pareto_frontier(X, Y):
    """
    X: Throughput (maximize)
    Y: Efficiency (maximize)
    Returns: indices of non-dominated points
    """
    is_pareto = np.ones(len(X), dtype=bool)
    for i in range(len(X)):
        for j in range(len(X)):
            if i != j:
                if X[j] >= X[i] and Y[j] >= Y[i]:
                    if X[j] > X[i] or Y[j] > Y[i]:
                        is_pareto[i] = False
                        break
    return np.where(is_pareto)[0]
```

---

## 5. SCELTE TECNICHE

### 5.1 Griglia Temporale

**DECISIONE:** Resample a **1 secondo (1Hz)**

**Motivazioni:**
- Allineamento naturale con vmstat, iostat, free, pidstat (gi√† 1s)
- RAPL a 0.5s ‚Üí Resample con mean/sum preserva informazione
- Riduce dimensione dataset (met√† punti vs 2Hz)
- Standard in energy profiling literature

**Implementazione:**
```python
def resample_to_grid(df, timestamp_col='timestamp', freq='1s'):
    """
    Resample DataFrame to uniform temporal grid

    Args:
        df: pandas.DataFrame with timestamp column
        timestamp_col: name of timestamp column
        freq: '1s' (1Hz), '0.5s' (2Hz), etc.

    Returns:
        Resampled DataFrame with uniform timestamps
    """
    df[timestamp_col] = pd.to_datetime(df[timestamp_col], unit='s')
    df = df.set_index(timestamp_col)
    df_resampled = df.resample(freq).mean()  # or .sum() for cumulative
    return df_resampled.reset_index()
```

**Opzione CLI:**
```bash
--resample 1s   # default
--resample 0.5s # massima risoluzione (se necessario)
```

### 5.2 Librerie Python

**Stack standard scientific Python:**

```python
# requirements.txt
pandas>=2.0.0          # DataFrame manipulation
numpy>=1.24.0          # Numerical computations
matplotlib>=3.7.0      # Plotting
seaborn>=0.12.0        # Statistical visualizations
scipy>=1.10.0          # Statistical tests (pearsonr, etc.)
```

**Motivazioni:**
- pandas: Standard per time-series analysis
- matplotlib: Publication-quality plots, altamente customizzabile
- seaborn: Statistical plots (correlation matrix, etc.)
- scipy: Statistical tests (Pearson, Spearman, KS test futuro)

### 5.3 Gestione Timestamp

**Formato input:** Unix epoch con decimali (float, secondi)
```
1763408270.057390106
```

**Conversione pandas:**
```python
df['timestamp'] = pd.to_datetime(df['timestamp'], unit='s')
# Result: datetime64[ns] type
```

**Calcoli temporali:**
```python
duration = (df['timestamp'].max() - df['timestamp'].min()).total_seconds()
```

### 5.4 Gestione Missing Values

**Strategia:**
1. **-1 values in pidstat:** Replace con NaN
2. **Missing timestamps:** Forward-fill (assume valore precedente)
3. **Outliers:** Winsorization (clip extreme values)

```python
# Replace -1 with NaN
df.replace(-1.0, np.nan, inplace=True)

# Forward fill for missing data
df.ffill(inplace=True)

# Outlier handling (optional)
from scipy.stats.mstats import winsorize
df['power_w'] = winsorize(df['power_w'], limits=[0.01, 0.01])
```

### 5.5 Formato Output

**Metriche:** JSON (machine-readable) + TXT (human-readable)

**metrics_summary.json:**
```json
{
  "experiment_id": "exp_20251117_203747",
  "duration_s": 305.7,
  "performance": {
    "throughput_samples_per_s": 393.5,
    "cpu_utilization_percent": 78.3,
    "memory_peak_mb": 2048.5,
    "ipc": 1.24,
    "cache_hit_rate_percent": 89.2
  },
  "energy": {
    "total_energy_j": 45678.9,
    "average_power_w": 149.4,
    "energy_per_1000_events_j": 380.2,
    "energy_breakdown": {
      "cpu_percent": 72.5,
      "dram_percent": 27.5
    }
  },
  "efficiency": {
    "performance_per_watt": 2.63,
    "samples_per_joule": 2.64,
    "energy_delay_product": 4.27e9
  },
  "monitoring_overhead": {
    "cpu_overhead_percent": 3.2,
    "memory_overhead_mb": 45.6,
    "tools": {
      "vmstat": 0.8,
      "iostat": 0.9,
      "pidstat": 0.7,
      "rapl": 0.5,
      "perf": 0.3
    }
  },
  "correlations": {
    "power_vs_gloss": {
      "pearson_r": 0.45,
      "p_value": 0.001,
      "interpretation": "Moderate positive correlation"
    },
    "freq_vs_power": {
      "pearson_r": 0.82,
      "p_value": 1.2e-15,
      "r_squared": 0.67,
      "regression": "P = 0.15√óf + 20.3"
    }
  },
  "workload_type": "compute-bound",
  "bottlenecks_detected": []
}
```

**LaTeX tables:** Per inclusione diretta in tesi

```latex
% energy_metrics.tex
\begin{table}[h]
\centering
\caption{Energy Metrics - exp\_20251117\_203747}
\begin{tabular}{lrr}
\toprule
Metric & Value & Unit \\
\midrule
Total Energy & 45.68 & kJ \\
Average Power & 149.4 & W \\
Energy/1000-events & 380.2 & J \\
CPU Energy \% & 72.5 & \% \\
DRAM Energy \% & 27.5 & \% \\
\bottomrule
\end{tabular}
\end{table}
```

---

## 6. STRUTTURA OUTPUT

### 6.1 Directory Structure

```
exp_YYYYMMDD_HHMMSS/
‚îú‚îÄ‚îÄ metadata/
‚îÇ   ‚îú‚îÄ‚îÄ experiment_metadata.json       # Configurazione esperimento
‚îÇ   ‚îî‚îÄ‚îÄ execution_summary.json         # Durata, timestamps
‚îú‚îÄ‚îÄ logs/
‚îÇ   ‚îú‚îÄ‚îÄ train_stdout.log              # Output training (Gloss, Dloss)
‚îÇ   ‚îî‚îÄ‚îÄ train_stderr.log              # Errori
‚îú‚îÄ‚îÄ system_monitoring/
‚îÇ   ‚îú‚îÄ‚îÄ train_system_energy_rapl.csv   # ‚ö° Dati energia
‚îÇ   ‚îú‚îÄ‚îÄ train_system_cpu_freq.csv      # Frequenza CPU
‚îÇ   ‚îú‚îÄ‚îÄ train_system_thermal.csv       # Temperature
‚îÇ   ‚îú‚îÄ‚îÄ train_system_vmstat.csv        # CPU, memoria
‚îÇ   ‚îú‚îÄ‚îÄ train_system_iostat_cpu.csv    # CPU stats
‚îÇ   ‚îú‚îÄ‚îÄ train_system_iostat_dev.csv    # I/O device
‚îÇ   ‚îú‚îÄ‚îÄ train_system_free_mem.csv      # Memoria
‚îÇ   ‚îú‚îÄ‚îÄ train_system_free_swap.csv     # Swap
‚îÇ   ‚îú‚îÄ‚îÄ train_system_pidstat.csv       # Top-10 processi
‚îÇ   ‚îî‚îÄ‚îÄ train_system_monitoring_overhead.csv  # üÜï Auto-monitoring
‚îú‚îÄ‚îÄ process_monitoring/
‚îÇ   ‚îú‚îÄ‚îÄ train_process_pidstat.csv      # Statistiche processo Python
‚îÇ   ‚îú‚îÄ‚îÄ train_process_io.csv           # I/O processo
‚îÇ   ‚îî‚îÄ‚îÄ train_process_perf.csv         # üÜï Performance counters CSV
‚îî‚îÄ‚îÄ analysis/                          # üÜï Output analisi
    ‚îú‚îÄ‚îÄ metrics_summary.json           # Tutte le metriche calcolate
    ‚îú‚îÄ‚îÄ energy_report.txt              # Report testuale energia
    ‚îú‚îÄ‚îÄ performance_report.txt         # Report testuale performance
    ‚îú‚îÄ‚îÄ monitoring_overhead_report.txt # Report overhead
    ‚îú‚îÄ‚îÄ plots/                         # Grafici
    ‚îÇ   ‚îú‚îÄ‚îÄ power_profile.png          # 1
    ‚îÇ   ‚îú‚îÄ‚îÄ power_profile_detailed.png
    ‚îÇ   ‚îú‚îÄ‚îÄ energy_breakdown.png       # 2
    ‚îÇ   ‚îú‚îÄ‚îÄ frequency_vs_power.png     # 3
    ‚îÇ   ‚îú‚îÄ‚îÄ memory_usage.png           # 4
    ‚îÇ   ‚îú‚îÄ‚îÄ thermal_analysis.png       # 5
    ‚îÇ   ‚îú‚îÄ‚îÄ monitoring_overhead.png    # 6
    ‚îÇ   ‚îú‚îÄ‚îÄ loss_evolution.png         # 7
    ‚îÇ   ‚îú‚îÄ‚îÄ power_vs_loss_evolution.png        # 8 üÜï
    ‚îÇ   ‚îú‚îÄ‚îÄ workload_characterization.png      # 9 üÜï
    ‚îÇ   ‚îú‚îÄ‚îÄ energy_performance_tradeoff.png    # 10 üÜï
    ‚îÇ   ‚îî‚îÄ‚îÄ performance_scalability.png        # 11 üÜï
    ‚îî‚îÄ‚îÄ tables/                        # Tabelle LaTeX
        ‚îú‚îÄ‚îÄ metrics_summary.tex
        ‚îú‚îÄ‚îÄ energy_metrics.tex
        ‚îú‚îÄ‚îÄ performance_metrics.tex
        ‚îî‚îÄ‚îÄ efficiency_metrics.tex
```

### 6.2 File Sizes Attesi

| File | Size (500 iter, ~6 min) | Note |
|------|-------------------------|------|
| `metrics_summary.json` | ~5 KB | Metriche aggregate |
| `energy_report.txt` | ~2 KB | Human-readable |
| All plots (11 PNG) | ~5-10 MB | 1920x1080, 300 DPI |
| LaTeX tables | ~2 KB | Per inclusione tesi |

---

## 7. ARCHITETTURA SOFTWARE

### 7.1 Moduli Python

```
analysis/
‚îú‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ utils.py                           # Helper functions
‚îú‚îÄ‚îÄ monitoring_data_loader.py          # CSV loading + validation
‚îú‚îÄ‚îÄ metrics_calculator.py              # Metriche 2.1-2.5
‚îú‚îÄ‚îÄ visualizer.py                      # Grafici 3.1-3.2
‚îú‚îÄ‚îÄ report_generator.py                # Reports + LaTeX
‚îú‚îÄ‚îÄ analyze_experiment.py              # CLI entry point
‚îî‚îÄ‚îÄ ANALYSIS_SPECIFICATION.md          # Questo documento
```

### 7.2 Classi Principali

#### `utils.py`

```python
def handle_rapl_overflow(energy_series: pd.Series) -> pd.Series:
    """Handle RAPL 32-bit counter overflow"""

def parse_stdout_losses(stdout_path: str) -> dict:
    """Parse Gloss, Dloss from stdout.log"""

def resample_to_grid(df: pd.DataFrame, freq='1s') -> pd.DataFrame:
    """Resample to uniform temporal grid"""

def safe_divide(num, den, default=np.nan):
    """Division with NaN handling"""
```

#### `monitoring_data_loader.py`

```python
class MonitoringDataLoader:
    """Load and preprocess all monitoring CSV files"""

    def load_experiment(self, exp_dir: str) -> dict[str, pd.DataFrame]:
        """Load all CSVs from experiment directory"""

    def _load_rapl_with_overflow(self, rapl_path: str) -> pd.DataFrame:
        """Load RAPL with overflow correction"""

    def _load_perf_csv(self, perf_path: str) -> pd.DataFrame:
        """Load perf CSV (new standard format)"""

    def _resample_all_to_grid(self, dfs: dict, freq='1s') -> dict:
        """Resample all DataFrames to uniform grid"""

    def validate_data(self, dfs: dict) -> dict:
        """Validate data integrity, check missing values"""
```

#### `metrics_calculator.py`

```python
class MetricsCalculator:
    """Calculate all metrics (sections 2.1-2.5)"""

    def compute_energy_metrics(self, rapl_df: pd.DataFrame) -> dict:
        """
        Returns: {
            'total_energy_j': float,
            'average_power_w': float,
            'energy_per_1000_events_j': float,
            'energy_breakdown': dict
        }
        """

    def compute_performance_metrics(self,
                                   pidstat_df: pd.DataFrame,
                                   vmstat_df: pd.DataFrame,
                                   perf_df: pd.DataFrame) -> dict:
        """CPU, memory, IPC, cache metrics"""

    def compute_efficiency_metrics(self,
                                   energy_dict: dict,
                                   perf_dict: dict) -> dict:
        """Performance-per-Watt, samples/Joule, EDP"""

    def compute_monitoring_overhead(self,
                                   overhead_df: pd.DataFrame,
                                   vmstat_df: pd.DataFrame) -> dict:
        """Monitoring CPU/memory overhead"""

    def parse_training_metrics(self, stdout_path: str) -> dict:
        """Parse Gloss, Dloss, throughput from stdout.log"""

    def compute_correlations(self,
                            dfs: dict,
                            metrics: dict) -> dict:
        """Pearson correlations for all pairs"""
```

#### `visualizer.py`

```python
class MonitoringVisualizer:
    """Generate all plots (section 3)"""

    def __init__(self, style='seaborn-v0_8', dpi=300):
        """Initialize with matplotlib style"""

    # Time-series plots
    def plot_power_profile(self, rapl_df, output_path):
        """Grafico 1: Power over time"""

    def plot_memory_usage(self, free_df, output_path):
        """Grafico 4: Stacked area memory"""

    def plot_thermal_analysis(self, thermal_df, rapl_df, freq_df, output):
        """Grafico 5: Multi-axis thermal+power+freq"""

    def plot_loss_evolution(self, training_metrics, output):
        """Grafico 7: Gloss, Dloss over iterations"""

    def plot_power_vs_loss_evolution(self, rapl_df, training_metrics, output):
        """Grafico 8: Dual-axis power + losses"""

    # Breakdown plots
    def plot_energy_breakdown(self, energy_dict, output_path):
        """Grafico 2: Pie chart CPU/DRAM"""

    def plot_monitoring_overhead(self, overhead_dict, output_path):
        """Grafico 6: Bar chart overhead per tool"""

    # Correlation plots
    def plot_frequency_vs_power(self, freq_df, rapl_df, output):
        """Grafico 3: Scatter + regression"""

    def plot_workload_characterization(self, perf_df, vmstat_df, output):
        """Grafico 9: IPC vs iowait scatter"""

    def plot_energy_performance_tradeoff(self, metrics_ts, output):
        """Grafico 10: Pareto frontier"""

    def plot_performance_scalability(self, vmstat_df, training_metrics, output):
        """Grafico 11: CPU% vs throughput"""

    # Utility
    def _apply_plot_style(self, ax):
        """Apply consistent styling to all plots"""
```

#### `report_generator.py`

```python
class ExperimentReport:
    """Generate reports and tables"""

    def generate_summary_table(self, metrics: dict) -> pd.DataFrame:
        """Create summary table from all metrics"""

    def generate_text_reports(self, metrics: dict, output_dir: str):
        """Generate energy_report.txt, performance_report.txt, etc."""

    def export_latex_tables(self, metrics: dict, output_dir: str):
        """Export LaTeX tables for thesis"""

    def generate_json_summary(self, metrics: dict, output_path: str):
        """Save metrics_summary.json"""
```

#### `analyze_experiment.py` (CLI)

```python
def main(exp_dir: str,
         resample: str = '1s',
         skip_plots: bool = False,
         latex_only: bool = False,
         output_dir: str = None):
    """
    Main analysis pipeline

    Args:
        exp_dir: Path to experiment directory
        resample: Temporal grid ('1s', '0.5s')
        skip_plots: Skip plot generation (faster)
        latex_only: Only generate LaTeX tables
        output_dir: Override default output directory
    """

    # 1. Load data
    loader = MonitoringDataLoader()
    dfs = loader.load_experiment(exp_dir)
    dfs = loader._resample_all_to_grid(dfs, freq=resample)

    # 2. Calculate metrics
    calc = MetricsCalculator()
    energy_metrics = calc.compute_energy_metrics(dfs['rapl'])
    perf_metrics = calc.compute_performance_metrics(dfs['pidstat'],
                                                    dfs['vmstat'],
                                                    dfs['perf'])
    efficiency_metrics = calc.compute_efficiency_metrics(energy_metrics,
                                                         perf_metrics)
    overhead_metrics = calc.compute_monitoring_overhead(dfs['overhead'],
                                                        dfs['vmstat'])
    training_metrics = calc.parse_training_metrics(f"{exp_dir}/logs/train_stdout.log")
    correlations = calc.compute_correlations(dfs,
                                            {**energy_metrics,
                                             **perf_metrics,
                                             **training_metrics})

    # 3. Generate plots
    if not skip_plots:
        viz = MonitoringVisualizer()
        plot_dir = f"{output_dir or exp_dir}/analysis/plots"
        os.makedirs(plot_dir, exist_ok=True)

        viz.plot_power_profile(dfs['rapl'], f"{plot_dir}/power_profile.png")
        viz.plot_energy_breakdown(energy_metrics, f"{plot_dir}/energy_breakdown.png")
        # ... all 11 plots

    # 4. Generate reports
    reporter = ExperimentReport()
    reporter.generate_json_summary(all_metrics, f"{output_dir}/metrics_summary.json")
    reporter.generate_text_reports(all_metrics, output_dir)
    reporter.export_latex_tables(all_metrics, f"{output_dir}/tables")

    print(f"‚úÖ Analysis complete: {output_dir}")
```

---

## 8. PIANO DI IMPLEMENTAZIONE

### 8.1 Phase 1: Core Infrastructure (Priority ‚≠ê‚≠ê‚≠ê) ‚úÖ COMPLETATA

**Obiettivo:** Caricare dati e calcolare metriche

| Step | File | Funzionalit√† | Stima | Status |
|------|------|--------------|-------|--------|
| 1.1 | `utils.py` | RAPL overflow, resample, stdout parsing | 2h | ‚úÖ DONE |
| 1.2 | `monitoring_data_loader.py` | Load all CSVs + validation | 3h | ‚úÖ DONE |
| 1.3 | `metrics_calculator.py` | All metrics 2.1-2.6 + correlations | 5h | ‚úÖ DONE |
| 1.4 | `test_e2e_pipeline.py` | Test completo su dati reali | 2h | ‚úÖ DONE |
| 1.5 | Dense logging implementation | Training log_interval separato | 2h | ‚úÖ DONE |
| 1.6 | Convergence metrics | 8 metriche GAN convergence | 1h | ‚úÖ DONE |

**Deliverable:** ‚úÖ **31/23 metriche (135% coverage)** + **6/6 correlazioni**

**Note implementazione:**
- Metriche oltre SPEC: convergence metrics complete, power profile, per-component breakdown
- Test E2E validati su esperimenti cluster reali
- Dense logging: 11-51 punti vs 6 originali

---

### 8.2 Phase 2: Visualizations (Priority ‚≠ê‚≠ê‚≠ê)

**Obiettivo:** Generare i TOP 11 grafici

| Step | Grafici | Stima | Status |
|------|---------|-------|--------|
| 2.1 | Time-series (#1, 4, 5, 7, 8) | 3h | ‚¨ú TODO |
| 2.2 | Breakdown (#2, 6) | 1h | ‚¨ú TODO |
| 2.3 | Correlations (#3, 9, 10, 11) | 3h | ‚¨ú TODO |
| 2.4 | Styling & consistency | 1h | ‚¨ú TODO |

**Deliverable:** 11 publication-quality plots

---

### 8.3 Phase 3: Reports & CLI (Priority ‚≠ê‚≠ê‚≠ê)

**Obiettivo:** CLI completo + LaTeX export

| Step | File | Funzionalit√† | Stima | Status |
|------|------|--------------|-------|--------|
| 3.1 | `report_generator.py` | JSON, TXT, LaTeX export | 2h | ‚¨ú TODO |
| 3.2 | `analyze_experiment.py` | CLI with argparse | 2h | ‚¨ú TODO |
| 3.3 | Integration test | Full pipeline on 500-iter experiment | 1h | ‚¨ú TODO |
| 3.4 | Documentation | README, docstrings | 1h | ‚¨ú TODO |

**Deliverable:** Fully functional analysis suite

---

### 8.4 Phase 4: Nice-to-Have (Priority ‚≠ê)

**Obiettivo:** Features aggiuntive se c'√® tempo

| Feature | Descrizione | Stima | Status |
|---------|-------------|-------|--------|
| 4.1 | Grafici 12-14 (cache, memory pressure, heatmap) | 2h | ‚¨ú OPTIONAL |
| 4.2 | HTML interactive report | Plotly graphs | 3h | ‚¨ú OPTIONAL |
| 4.3 | Multi-experiment comparison | Compare multiple runs | 4h | ‚¨ú FUTURE |
| 4.4 | Evaluation metrics integration | œá¬≤/NDF, Wasserstein | 3h | ‚¨ú FUTURE |

---

### 8.5 Testing Strategy

**Test Data:** `results/monitoring/exp_20251117_203747` (500 iterations, ~6 min)

**Validation Checklist:**
- [ ] All CSVs load correctly
- [ ] RAPL overflow handled (check energy total is monotonic)
- [ ] Timestamps aligned (all DataFrames same length after resample)
- [ ] Metrics in reasonable ranges:
  - [ ] Power: 100-200W (dual-socket Xeon)
  - [ ] CPU%: 50-95% (training workload)
  - [ ] Memory: 1-4 GB (BoloGAN footprint)
  - [ ] IPC: 0.5-2.0 (typical ML workload)
- [ ] All 11 plots generated without errors
- [ ] JSON validates (well-formed)
- [ ] LaTeX tables compile in LaTeX document

---

## 9. CHANGELOG

### v1.1 - 2025-11-18 (Phase 1 Implementation Complete)
- ‚úÖ **Phase 1 completata al 100%**
- ‚úÖ Implementati 4/5 moduli core: `utils.py`, `monitoring_data_loader.py`, `metrics_calculator.py`, `test_e2e_pipeline.py`
- ‚úÖ **31/23 metriche SPEC** (135% coverage):
  - Performance: 9/9
  - Energy: 6/4 (bonus: per-component, power_profile)
  - Efficiency: 3/3
  - Overhead: 3/3
  - Convergence: 8/3 (NUOVO! oltre SPEC)
  - Derived: 5/3
- ‚úÖ **6/6 correlazioni** complete (C1-C8)
- ‚úÖ Dense logging implementato (11-51 punti vs 6 originali)
- ‚úÖ Test E2E validati su dati cluster reali
- ‚úÖ Selective training output copy implementata
- ‚è≥ Rimangono: Visualizer (11 plots), Report Generator, CLI

### v1.0 - 2025-11-18 (Initial Specification)
- ‚úÖ Definite 25 metriche (Performance, Energy, Efficiency, Overhead, ML)
- ‚úÖ Definiti TOP 11 grafici must-have
- ‚úÖ Aggiunti 3 grafici originali (Power vs Loss, Workload Characterization, Pareto)
- ‚úÖ Scelte tecniche: 1s resample, pandas/matplotlib/seaborn stack
- ‚úÖ Architettura software: 5 moduli Python
- ‚úÖ Piano implementazione: 4 fasi (Core, Viz, Reports, Optional)

---

## 10. RIFERIMENTI

### 10.1 Paper & Standard

- **MLPerf Power**: https://mlcommons.org/en/groups/research-power/
- **Green AI**: Schwartz et al. "Green AI" (2019)
- **Energy-Delay Product**: Gonzalez & Horowitz, IEEE JSSC 1996
- **RAPL**: "RAPL in Action" (Intel 2014)

### 10.2 Documentazione Interna

- `results/oph/monitoring/MONITORING_DATA_ANALYSIS.md` - Formato dati
- `scripts/enhanced_wrapper.sh` - Sistema monitoring
- `struttura della tesi.pdf` - Capitolo 3 requirements

### 10.3 Tools

- pandas documentation: https://pandas.pydata.org/
- matplotlib gallery: https://matplotlib.org/stable/gallery/
- seaborn examples: https://seaborn.pydata.org/examples/

---

**Fine Specifica - Ready for Implementation** üöÄ
